
# 数据结构

### `Redis` 有几种数据结构？`Zset` 是如何实现的？

#### 几种数据结构

- `Redis`基本的数据结构，有5种，分别是：`String`(字符串)、`Hash`(哈希)、`List`(列表)、`Set`(集合)、`Zset`(有序集合)
- `Redis`常见类型的底层数据结构有8种，分别是：`int、embstr、raw、hashtable、ziplist、quicklist、intset、skiplist`

#### `Zset` 是如何实现的？

- `Zset`的底层数据结构有两种，分别是`ziplist`(压缩列表)和`skiplist`(跳表)
- `Zset`使用`ziplist`满足两个条件，否则使用`skiplist`
  - 所有元素的长度小于64字节(`server.zset_max_ziplist_value`配置)
  - 元素的个数小于128个(`server.zset_max_ziplist_entries`配置)

##### 当`ziplist`作为`zset`的底层存储结构

- 每个`zset`元素使用紧挨在一起的压缩列表结点保存，第一个结点保存`member`，第二个元素保存`score`，分值小的靠近表头
- `zadd`过程：
  - 通过顺序查找，`member`是否存在，如果存在，则先删除
  - 如果不存在，则向`ziplist`添加两次插入，插入后需要考虑元素的长度或个数是否超过限制，如果超出，则将底层结构转换为`skiplist`

##### 当`skiplist`作为`zset`的底层存储结构时

- 此时`zset`的底层实现是跳表结合哈希表。
  - 每个跳跃结点保存一个`Zset` 元素，并按分值从小到大排序，同时保存`member`和`score`的值
  - 字典的每个结点保存一个`Zset` 的元素，`member`为`key`，`score`为`value` 
  - `member`和`score`值是共享的，跳跃表和字典通过指针指向同一地址，不会浪费内存
- `zadd`的查找过程：
  - 先通过哈希表查找`member`是否存在，此操作时间复杂度为`O(1)`，如果存在则需要查找结点在跳跃表的位置；
  - 跳跃表是有序存储，从头结点的最高层开始遍历查找，如果没有找到目标结点，则从最后一个比目标结点`score`小的结点开始降一层再遍历，直到找到目标结点；
  - 然后将哈希表键值对和`skiplist`结点数据删除
  - 然后进行插入操作
- `zadd`的插入过程
  - 通过`score`查找到新增结点应该插入的位置；
  - 随机生成结点的层数，使用该层数新建一个跳跃结点；
  - 更新新增结点所在位置的前后结点指针，将新增结点插入到`skiplist`

------

### 简述 `Redis` 中跳表的应用以及优缺点

------

### 简述 `Redis` 中常见类型的底层数据结构

##### `String`(字符串)

- `Redis`字符串叫做`SDS`(简单动态字符串)，其结构是一个带有长度和容量信息的字节数组，其对应的底层数据结构是：`int`(整数)、`embstr`编码简单动态字符串、`raw`简单动态字符串
- 使用`int`存储的条件是，`value`长度小于`20`并且可以解析为整数；
- 使用`embstr`编码简单字符串存储的条件是，`value` 的长度`<=44`，该对象会使用`malloc` 方法一次分配内存，将`redisObject`对象头和`SDS`对象连续存在一起
- 不满足上述条件，则用`raw`简单动态字符串存储，需要两次`malloc`分配内存，`redisObject`对象头和`SDS`对象在内存地址上一般是不连续的

##### `Hash`(哈希)

- `Hash`的底层数据结构有两种，分别为`ziplist`(压缩列表)和`hashtable`(哈希表)
- 哈希对象使用`ziplist`存储数据需要同时满足两个条件，否则使用`hashtable`
  - 所有键值对的键和值的字符串长度小于64字节(`server.hash_max_ziplist_value`配置)
  - 键值对数量小于512个(`server.hash_max_ziplist_entries`)
- 压缩列表是一块连续的内存空间，实现类似数组，`key-value`键值对以紧密相连的方式存入压缩链表，没有任何冗余空隙；压缩链表支持双向遍历；
- `hashtable`通过分桶的方式解决`hash`冲突，第一维是数组，第二维是链表。数组中存储的是第二维链表的第一个元素的指针
  - 每个哈希底层包含两个`hashtable`，通常情况下只有一个`hashtable`是有值的
  - 在`hash`扩容缩容时，需要分配新的`hashtable`用于渐进式`rehash`

##### `List`(链表)

- 列表对象的底层数据结构有过3种，分别是：`linkedlist`(双向链表)、`ziplist`(压缩列表)、`quicklist`(快速列表)
- `linkedlist`(双向链表)底层采用双端链表实现，需要附加空间相对太高(`prev`和`next`指针占16字节)，在`3.2`版本以后就废弃了
- `quicklist`是底层采用双端链表结构，不过每个链表结点都保存一个``ziplist``，每个`ziplist`的长度为`8kb`；

##### `Set`(集合)

- 集合对象的底层数据结构有两种：`intset`(整数集合)和`hashtable`(哈希表)
- 集合使用`intset`需要满足两个条件，否则使用`hashtable`
  - 所有元素都是整数
  - 集合中的元素个数不超过512个(`server.set_max_intset_entries`配置)
- `intset`用于保存整数数值的集合抽象数据结构，不会出现重复元素，底层实现为数组；
- `hashtable`的所有`value`都是`NULL`；

##### `Zset`(有序集合)

- `Zset`的底层数据结构有两种：`ziplist`(压缩列表)和`skiplist`(跳表)
- `Zset`使用`ziplist`满足两个条件，否则使用`skiplist`
  - 所有元素的长度小于64字节(`server.zset_max_ziplist_value`配置)
  - 元素的个数小于128个(`server.zset_max_ziplist_entries`配置)
- 当`ziplist`作为`zset`的底层数据结构时，通过成员-分数方式存储，分值小的靠近表头
- 当`skiplist`作为`zset`的底层数据结构时，会结合`hashtable`，便于判断`member`是否存在
  - 每个条约结点都保存一个`zset`元素，并按分值从小到大排序，如果分值相同，则按照成员对象的大小排序
  - 哈希表的每个结点保存一个`Zset` 的元素，`member`为`key`，`score`为`value` 


##### 拓展：`embstr`为什么最大存储`44`个字符

- 在`Redis`中，每个对象都是由`RedisObject`结构表示：
  - `RedisObjec`主要包括的的内容为：
  - 对象的类型(`type 4bits`)、对应的底层数据结构(`encoding 4bits`)、`LRU`信息(`LRU 3bytes`)、引用计数器(`refcount 4byte`)、指向对象内容存储地址的指针(`*ptr`)
  - 共占 `16`个字节
- 字符串是`SDS`(简单动态字符串)，其中存储字节的数组外，还要容量(`capacity`)、长度(`len`)、标识符(`flags`),在字符串比较小时，这三个字段占用`3`个字节
- 字符串的存储字节数组是以`\0`结尾，占用`1`个字符
- `Redis`认为超过`64`个字节的字符串是一个大字符串，需要使用`raw`，所有`embstr`最大存储是`44=64-16-3-1`字符
- 存储形式的差别
  - `embstr` 存储形式：将`RedisObject`对象头和`SDS`对象连续存在一起，使用 `malloc` 方法一次分配
  - `raw` 存储形式：需要两次`malloc`，`RedisObject` 对象头和 `SDS` 对象在内存地址上不连续

#### 拓展：渐进式`rehash`

- 为了解决一次性`rehash`会造成线程卡顿问题，`Redis`渐进式`rehash`
- 它会同时保留旧数组和新数组，然后在定时任务以及后续对`hash`的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。
- 这意味着要操作处于`rehash`中的字典，需要同时访问新旧两个数组。
- 如果在旧数组找不到元素，还需要去新数组下面去寻找

------

### `Redis` 如何实现延时队列?

- 延时队列可以通过 `Redis` 的 `zset` 来实现。
- 我们将消息序列号一个字符串作为 `zset` 的 `value`，这个消息的到期处理时间作为 `score`，然后用多线程轮询 `zset` 获取到期的任务进行处理。
- 多线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。
- 因为有多线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。
- `zset` 的 `zrem` 方法是多线程争抢任务的关键，它的返回值决定了当前线程有没有抢到任务。

##### 拓展：重试机制

- 如果线程抢到任务后，执行失败(如：更新事务失败)，需要考虑到重试机制
- 可将任务重新 `zadd` 回到延时队列中，设置下一次执行的时间，但要考虑到不能无限重试，所以消息内容最好带重试了几次，以控制频率。
- 如果该任务是处理多个子任务，还需要考虑到幂等操作，例如：更新业务时，先查询该任务是否已经存在记录。

------

### `Redis` 分布式锁的实现原理？

- 使用分布式锁的目的，帮助不同进程以互斥的方式使用共享资源。
- `Redis`的分布式锁实现方案，分为单个实例和多个实例

##### 单个实例

- 获得锁的方式：`SET key value NX EX 10`
  - `NX`：就是 `setnx`，仅不 `key`, 不存在才可以被赋值
  - `EX 10`: 增加过期时间是为了解决死锁问题，因为进程在执行期间可能发生故障，锁得不到释放
  - `value`：该值表示拥有锁的客户端标识，这个标识可以使用客户端`ID` + 微秒级时间戳
- 为什么要设置客户端标识？
  - 客户端`A`获取该锁后，在某些操作中被阻塞时间超过该锁的有效时间，导致锁被释放掉。
  - 客户端`B`在获取锁后，进行其他操作时，客户端`A`完成操作后，会删除客户端`B`以及获取的锁。
  - 增加客户端标识的目的是为了线程安全，客户端`A`在删除锁时，需要先判断该锁释放属于自己

- 删除锁：先判断，后删除，必须原子操作，需使用 `Lua` 脚本

  ```lua
  if redis.call("get", KEYS[1] == ARGV[1]) then
  	return redis.call("del", KEY[1])
  else
  	return 0
  end
  ```

##### 为什么要多个`Redis master` 节点

- 因为`Redis` 的复制是异步的
- 假如客户端`A`获得主服务器期间，在主从同步前，主机崩溃，这时客户端`B`可以获取该锁，导致不安全。
- 所以，在特殊情况下(如：故障)，多个客户端可以同时持有锁会保证资源的安全性。

##### 多个实例-`Redlock`算法

- 假设有`N` 个 `Reids master`，这些节点完全独立，不使用复制，客户端执行过程：
  - 获取当前时间设为 `T1`，设该锁的过期时间为 `10s`
  - 通过遍历，使用相同的`key` 和客户端标识来获取锁，获取当前锁的时间戳是`T2`，锁的存活时间为`T3 = 10 + T1 - T2` 。
  - 当客户端获取半数`(N/2+1)` 以上的锁，则证明获取该分布式锁。
- 故障考虑
  - 为了防止客户端长时间与故障状态的`Redis`节点通信时保持阻塞，客户端应设置合理的超时时间，如果一个实例不可用，我们应该尝试与下一个实例尽快通信
- 释放锁
  - 只需要在所有实例中释放锁，无论客户端之前是否成功获取分布式锁。

------

### 简述布隆过滤器原理及其使用场景

##### 原理

- 布隆过滤器是一个大型的位数组和几个不一样的无偏哈希函数组成。(无偏就是能够把元素的哈希值算得比较均匀)
- 向布隆过滤器中添加`key`时：
  - 会使用多个哈希函数对`key`进行哈希运行，每个哈希函数算得一个整数索引值，然后对位数组长度进行取模运算得到一个位置。
  - 再把数组的这几个位置设为1，这就完成了`add`操作
- 向布隆过滤器查询`key` 是否存在：
  - 跟`add`一样，会通过哈希函数算出几个位置，判断位数组这个几个位置是否都为1
  - 如果有一个位为0，说明布隆过滤器中这个`key`不存在
  - 如果都是1，并不能说明这个`key`就一定存在，只是极有可能存在，因为这些位置，可能是因为其他`key`存在所致
- 使用布隆过滤器时，不要让实际元素远大于初始化大小，当实际元素开始超过初始化大小时，应该对布隆过滤器进行重建，重新分配一个`size`更大的过来，再将所有的历史元素批量`add`进去。

##### 应用场景

- 爬虫系统，对`URL`进行去重
- 邮箱系统，垃圾邮件过滤
- 热点数据查询，防止缓存穿透

------

# 数据保存

### 简述 `Redis` 持久化中 `rdb` 以及 `aof` 方案的优缺点

#### RDB

- RDB持久化按照指定的时间间隔，以快照的形式进行数据备份

##### RDB的优势

- 因为RDB文件非常紧凑，所以非常适合备份，可以传输到外部用于灾备；
- RDB无需占用父进程IO，因为在备份过程中，父进程唯一要做的事情就是fork出一个子进程，子进程会处理所有的保存工作，无须占用父进程I/O操作
- RDB在恢复大数据集的速度要比AOF快

##### RDB的缺点

- RDB没办法做到实时持久化，如果服务器发生宕机，则会造成某个时间段内的数据丢失
  - 比如我们设置10分钟同步一次或者5分钟到达1000次写入就同步一次，那么如果还没达到触发条件，服务器死机了，这个时间段的数据会丢失
- RDB持久化过程中对服务性能影响大；
  - 使用bgsave命令在fork子进程时，如果数据量太大，fork的过程也会发生阻塞，另外，fork子进程会消耗内存

#### AOF

- AOF是以追加的形式记录每个写入操作

##### AOF的优点

- AOF可以实时持久化，数据更完整，具有多种备份策略(完成不同步、每秒同步[默认]、每次操作同步)
  - 即使服务宕机也仅会损失一秒钟的写入时间
  - 同时AOF增加日志的方式是追加操作，即使在写日志的过程中服务器宕机，也可以通过redis-check-aof工具修复
- AOF 日志太大时，Redis可以在后台自动重写AOF，且重写是完全安全的
- AOF容易理解和分析，适合紧急修复误操作
  - 假如不小心删错数据，可以通过停止服务器，删除最新命令并重新启动Redis来进行恢复

##### AOF的缺点

- 相同数据量下，AOF文件通常体积比RDB大
  -  因为AOF是存指令的，而RDB是所有指令的结果快照
- 在大量写入和载入的时候，AOF的效率会比RDB低
  - 因为大量写入，AOF会执行更多的保存命令；
  - 载入的时候也需要大量的重执行命令来得到最后的结果

##### AOF 重写

- fork子进程将内存数据转为写入命令，写入临时文件
  - 例如：list数字为["A", "B", "C"] 转化为 RPUSH list "A" "B" "C"
- 父线程在处理命令时，会将数据同步写入"AOF重写缓冲区"
  - 父线程有两个缓冲区：AOF缓冲区，AOF重写缓冲区
- 子进程写入完毕，通知父进程，父进程将 AOF 重写缓冲区数据写入 AOF临时文件，然后进行替换
  
#### 拓展：重启加载哪个文件

- 重启`Redis`，很少使用`RDB`来恢复内存状态，因为会丢失大量数据；
= 通常使用`AOF`日志重放，但重放`AOF`日志性能相对于`RDB`来说要慢很多，重启花费很长时间
- `Redis 4.0`加入混合持久化，`aof-use-rdb-preamble`开启
  - 将 `RDB`文件的内容和增量的`AOF`文件存放在一起，`AOF`不再是全量的日志，而是自持久化开始到当前这段时间发生的增量`AOF`
  - 于是在`Redis`重启时，可以线加载`RDB`的内容，然后再重放`AOF`内容。

#### 拓展：持久化策略的选择

- 如果`Redis`中的数据完全丢弃也没关系(如：`Redis`完全用作`DB`层数据的`cahce`)：
  - 那么无论是单价，还是主从架构，都可以不进行任何持久化；
- 如果在单机环境下(对于个人开发者)，如果可以接受十几分钟或更多的数据丢失：
  - 选择`RDB`对`Redis`的性能更加有利；
  - 如果只能接受秒级别的数据丢失，应该选择`AOF`
- 如果配置主从环境，`salve`的存在既可以实现数据的热备，也可以进行读写分离分担`Redis`读请求，以及在`master`宕机后继续提供服务：
 - `master`:完全关闭持久化`(包括`RDB`和`AOF`)，这样可以让`master`的性能达到最好
 - `slave`：开启`RDB`和`AOF`
 - `TODO`

#### 拓展：`RDB`的持久化操作

- `RDB`是一种快照存储持久方式，将`Redis`某一时刻的内存数据保存到硬盘的文件中，默认保存的文件名`dump.rdb`;

- 触发命令：`save`(阻塞当前进程)、`bgsave`(不阻塞，对`save`的优化)

- 触发机制
  - 手动触发
  - 配置`redis.conf save 900 1`：表示900秒内数据集存在1次修改，自动触发`bgsave`
  - 如果从节点执行全量复制操作，主节点自动执行`bgsave` 生成 `RDB`文件发送给从节点
  - 执行`debug reload`命令重载`Redis`，会触发`save`操作

- 执行流程
  - 执行`bgsave`命令，`Redis`父进程判断当前是否存在正在执行的子进程，如`RDB/AOF`子进程，如果存在`bgsave`命令直接返回
  - 父进程执行`fork`操作创建子进程，`fork`操作过程中父进程会阻塞;
  - 父进程`fork`完成后，`bgsave`命令返回`Background saving stared`信息并不再阻塞父进程，可以继续响应其它命令；
  - 子进程创建`RDB`文件，根据父进程内存生成临时快照文件，完成后原有文件进行原子替换；
  - 进程发送信号给父进程表示完成。

#### 拓展：`AOF`的持久化操作

- `AOF` 持久化方式会记录客户端对服务器的每一次写操作命令到日志当中，并将这些操作以`Redis`协议追加保存到，后缀为`aof`文件末尾

- 触发`AOF`重写流程
  - 如果当前进程正在执行`AOF`重写，请求不执行并返回`ERR`
  - 父进程执行`fork`创建子进程，开销等同于`bgsave`过程
    - 主进程`fork`操作完成后，继续响应其它命令。修改命令依然写入`AOF`缓冲区并根据`appendfsync`策略同步到硬盘，保证原有`AOF`机制正确性
    - 由于`fork`操运用写时复制技术(`COW`)，子进程只能共享`fork`操作时的内存数据。
    - 由于父进程依然响应命令，`Redis`使用`AOF`重写缓冲区保存这部分数据，防止新`AOF`文件生成期间丢失这部分数据
  - 子进程根据内存快照，按照命令合并规则写入新的`AOF`文件
    - 新`AOF`文件写入完成后，子进程发送信号给父进程
    - 父进程把`AOF`重写缓冲器的数据写入到新的`AOF`文件
    - 使用新`AOF`文件替代老文件，完成`AOF`重写

------

### `Redis` 序列化有哪些方式？

TODO

------

### 简述 `Redis` 的过期机制和内存淘汰策略

##### 过期机制

- `Redis`会将每个设置了过期时间的`key`放入一个独立的字典中，以后会定时扫描这个字典来删除到期的`key`。
- 除了定时遍历外，还会使用惰性策略来删除过期的`key`，所谓惰性策略就是在客户的访问这个`key` 时，`Redis`会对 `key`的过期时间进行检查，如果过期了就立即删除。
- 定时删除是集中处理，惰性删除是零散处理

##### 定期扫描策略

`Redis` 默认每 `100ms` 采用一一种简单的贪心策略进行扫描

1. 从过期字典中随机20个`key`;
2. 删除这20个`key`中已经过期的 `key`;
3. 如果过期的`key`比率超过 `1/4`，那么重复步骤1；
4. 为了保证过期扫描不会过度重复，导致线程卡死，扫描时间上限默认不会超过`25ms`

##### 内存淘汰机制

为了限制最大使用内存，当实际内存超出 `maxmemory`时，`Redis`提供了几种可选策略(`maxmemory-policy`) 来让用户自己决定该如何腾出新的空间以继续提供读写服务

- `noeviction`：不会继续服务写请求(`DEL`除外)，读请求可以继续，保证不会丢失数据，但会让线上的业务不能持续进行。这是默认的淘汰策略
- `volatile-lru`：从设置了过期时间的`key`中，最少使用的 `key`优先被淘汰。保证没设置过期时间的 `key` 不会被淘汰
- `volatile-ttl`：从设置了过期时间的`key`中，剩余存活时间(`ttl`)最短的被淘汰
- `volatile-random`：从设置了过期时间的`key`中，随机淘汰
- `allkeys-lru`：和 `volatile-lru` 的区别是从全体`key` 中选择
- `allkeys-ttl` : `volatile-ttl` 的区别是从全体`key` 中选择
- `allkeys-random` : `volatile-rand` 的区别是从全体`key` 中选择

`allkeys-xxx`只适合做缓存，如果想使用持久化，就要用 `volatile-xxx`

------

### 假设 `Redis` 的 `master` 节点宕机了，你会怎么进行数据恢复？

TODO

------

# 高可用

### 简述一致性哈希算法的实现方式及原理


##### 一致性哈希解决的问题

- `hash` 取模的方式，在缓存系统增加缓存或减少节点时，导致大量的缓存命不中；
- 缓存数据需要重新建立，甚至是整体的缓存数据迁移，瞬间会给 `DB`带来极高的系统负载，甚至导致 `DB`服务器宕机

##### 原理

- 一致性哈希，是一种特殊的哈希算法。
- 在使用一致哈希算法后，哈希表槽位数(大小)的改变平均只需对 `k/n`个关键字重新映射，`k`是`key`的数量，`n`是`Server`的数量。
- 在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射；

##### 实现

- 一致性哈希将整个哈希值空间组织成一个虚拟的圆环，假设某哈希函数 `H` 的值空间是 `0-2^32-1`(哈希值是32位无符号整形)；
- 整个空间按顺时针方向组织，`0`和`2^32-1`在零点方向重合。
- 将各个服务器的 `ip`或主机名 为关键字用 `H` 进行一个哈希计算，确定每台机器在环上的位置；
- 将数据 `key` 使用相同的函数 `H` 计算出哈希值 `idx`, 然后根据`idx`确定此数据在环上的位置，从此位置沿环顺时针行走，第一台遇到的服务器就是其应该定位到的服务器。

##### 容错性与可扩展性分析

- 容错性
  - 假如有三台服务器 `Server1、Sever2、Server3` 分别落在环上，通过`H`算法将`A`存放在 `Server1`、`B`存放在`Server2`，`C`存放在`Server3`；
  - 假设 `Server 3`宕机了，`A、B`节点不会受影响，`C`会顺着环往下走，遇到了`Server 1`；
  - 在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅是此服务器到其环空间中前一台服务器(逆时针方向第一台)之间的数据，其它不会受到影响
  
- 可扩展性分析
  - 接上面的情况，现在想增加一台 `Server 4`在 `Server 3`位置，则`C`会被重新定位到 `Server 4` 上；
  - 如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器(逆时针方向第一台)之间的数据，其它不受影响
  
- 综上所述，一致性哈希算法对节点的增减都只需重定位环空间的一小部分数据，具有较好的容错性和可扩展性

##### 存在问题

- 上面部分主要是面向`Redis`节点较多和节点分布较为均衡的情况，如果节点较少就会出现节点分布不均衡造成数据倾斜问题；
- 假如我们的系统有两台`Redis`，服务器落在环上的位置比较近，会产生一种情况，`Server 1` 的`hash`范围比`Server 2`的`hash`范围大，导致数据大部分都存储在`Server 1`中，数据存储不平衡；

##### 虚拟节点

- 为了解决这种数据存储不平衡的问题，一致性哈希算法引入虚拟节点机制，即对每个节点计算多个哈希值，每个计算结果位置都放置在对应节点中，这些节点称为虚拟节点；
- 例如：`Server 1` 可以编号为 `Server1#1`、`Server1#2`
- 在实际应用中，通常将虚拟节点数设置为 32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

------

### 简述 `Redis` 中如何防止缓存雪崩和缓存击穿

##### 缓存击穿的含义

- 某个热点数据失效，大量针对这个数据的请求会穿透到数据源，也就是大量请求到了`DB`，如果此时有大量的并发请求过来，会导致`DB`被压垮

##### 缓存击穿的解决方案

- 设置多久缓存(比如本地缓存和二级缓存)
- 使用互斥锁(分布式锁)更新，保证同一个进程针对同一个数据不会并发请求到 `DB`，减小`DB`压力
- 使用随机退避方法，失效时随机 `sleep` 一个很短的时间，再次查询，如果失败再执行更新。

##### 缓存雪崩含义：

- 原因
  1、`Redis` 挂掉，请求全部走数据库
  2、对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库
- 原因1解决方案
  - 事发前：实现 `Redis` 的高可用(主从架构 + `Redis Cluster`)，尽量避免 `Redis` 挂掉这种情况
  - 事发中：万一 `Redis` 挂掉，可以设置本地缓存 + 限流，尽量避免数据库被干掉(起码能保证服务还是能正常工作)
  - 事发后：`Redis` 持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据
- 原因2解决方案
  针对多个热点 `key` 同时失效问题，可以在缓存时使用固定时间加上一个小的随机数，避免大量热点 `key` 同一时刻失效 

##### 拓展：缓存穿透

- 缓存穿透含义：
  - 查询一个一定不存在的数据。由于缓存不命中，并且处于容错考虑，如果从数据库查不到则不写入缓存，这导致不存在的数据每次请求都要到数据库去查询，失去缓存的意义。
  - 请求数据大量不命中，导致请求走了数据库，产生这个问题的原因可能是外部的恶意攻击

- 缓存穿透的解决方案：
  - 接口层增加校验，用户鉴权校验，参数校验
  - 从数据库找不到时，也将空对象设置到缓存里，给空对象设置一个较短的过期时。

- 存在问题
  - 如果有大量获取未注册用户信息的请求，缓存内就会有大量的空值缓存，也就会浪费缓存的存储空间，空间被占满，还会剔除一些已被缓存的用户信息，反而会造成缓存命中率降低
  - 使用 `BloomFilter` 布隆过滤器(位数组)，特点是存在性检测，判断 `key` 是否在数据库中存在，如果不在 `BloomFilter` 中不存在，则数据也一定不存在。适合解决这类的问题。(时间复杂度`O(1)`)
  
- 布隆过滤器使用场景：资讯app的新闻展示，给用户推送新的资讯用来过滤哪些用户已经浏览过了

##### 拓展：`Linux`惊群效应

- 也叫雷鸣群体效应；
- 就是多进程(多线程)在同时阻塞等待同一个事件的适合(休眠状态)，如果等待的这个事件发生，那么它就会唤醒等待的所有进程(或者线程)；
- 但最终却只能有一个进程(线程)获得这个时间的控制权，对该事件进行处理；而其他进程(线程)获取控制权失败，只能重新进入休眠状态；
- 这种现象和性能浪费就叫惊群效应。

------

### 简述 `Redis` 的哨兵机制



------

### `Redis` 中，`sentinel` 和 `cluster` 的区别和适用场景是什么？

TODO

------

# 特性

### 为什么 `Redis` 在单线程下能如此快？

- 纯内存操作，`Redis`将数据存储在内存中，读写数据是都不会收到磁盘`I/O`的限制；
- 灵活多样的数据结构，针对不同的场景使用对于的数据类型，减少内存使用的同时，节省网络流量传输；
- 单线程操作，避免上下文切换和竞争条件，不用考虑各种锁的问题，如：释放锁、死锁等；
- 采用了非阻塞`I/O` 多路复用机制；
- 使用底层模型不同，`Redis` 直接自己构建了`VM`机制，减少调用系统函数的时间浪费

##### 拓展：`Redis`的非阻塞`I/O`多路复用机制

- `Redis`会将每个客户端套接字都关联一个指令队列。客户端的指令队列排队过来进行顺序处理，先到先得；
- `Redis` 也会为每个客户端套接字关联一个响应的队列。`Redis`服务器通过响应队列来将指令的返回结果回复给客户端。
- 如果响应队列为空，意味着连接暂时处于空闲状态，不需要去获取写事件，可以将当前客户端的描述符从 `write_fds`里移出来。等队列有数据了，再将描述符放进去。

##### 拓展：`Redis`的`VM`机制

- `Redis` 的 `VM`(虚拟内存)机制是，暂时把不经常访问的数据(冷数据)从内存交换到磁盘中；
- 通过`VM`功能实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘中。这样可以避免因为内存不足而造成访问速度下降的问题；
- `Redis`为了保证查找的速度，只会将`value`交换出去，而在内存中保留所有的`Key`。所以非常适合`Key`很小、`value `很大的情况；
- `Redis`并没有使用 `OS`提供的 `Swap`，而是自己实现

------
