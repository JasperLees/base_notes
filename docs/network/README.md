## `TCP`

### 简述 `TCP` 三次握手以及四次挥手的流程。为什么需要三次握手以及四次挥手？

##### 三次握手

- 刚开始客户端处于 `CLOSED`的状态，服务器监处于`LISTEN`状态
- 第一次握手：客户端给服务端发一个`SYN`报文：`(SYN，seq=x)`
  - 并指定客户端的初始化序号`ISN(c)`，此时客户端处于`SYN_SEND`状态；
- 第二次握手：服务器收到客户的`SYN`报文后：`(SYN seq=y, ACK ack=x+1)`
  - 会以自己的`SYN`报文作为应答，并且也是指定了自己的初始化序列号`ISN(s)`；
  - 同时会把客户端的`ISN+1`作为`ACK`的值，表示自己已经收到了客户端的`SYN`；
  - 此时服务器处于`SYN_REVD`的状态；
- 第三次握手：客户端收到`SYN`报文后：`(ACK seq=x+1, ack=y+1)`
  - 也同样会把服务器的`ISN+1`作为`ACK`的值，表示已经收到了服务器的`SYN`报文；
  - 此时客户端处于`ESTABLISHED`状态
- 服务器收到`ACK`报文后，也处于`ESTABLISHED`状态，此时，双方以建立起了连接

##### 四次挥手

- 刚开始双方都处于`ESTABLISHED`状态，假如是客户端先发起关闭请求，则：
- 第一次挥手：客户端发送一个`FIN`报文，报文中会指定一个序列号:`(FIN seq=p)`
  - 此时客户端处于`FIN_WAIT1`状态；
- 第二次挥手：服务端接收到`FIN`后：`(ACK ack=p+1)`
  - 会发送`ACK`报文，且把客户端的序列号值 `+1`作为`ACK`报文的序列号值，表明已经收到客户端的报文了；
  - 此时服务端处于`CLOSE_WAIT`状态
  - 客户端接收到`ACK`报文后，状态改变为`FIN_WAIT2`
- 第三次挥手：如果服务端也想断开连接了：
  - 和客户端第一次挥手一样，发送`FIN`报文，且指定一个序列号；
  - 此时服务端处于`LAST_ACK`的状态；
- 第四次挥手：客户端接收到`FIN`后：
  - 把客户端的序列号值`+1`作为自己`ACK`报文的序列号值，发送给服务端；
  - 此时客户端处于`TIME_WAIT`状态，需要过一阵子以确保服务器收到自己的`ACK`报文后才会进入`CLOSED`状态
- 服务端收到`ACK`报文后，就处于关闭连接了，处于`CLOSED`状态。

##### 为什么需要三次握手

- 因为三次握手才能确认双方的接收与发送能力是否正常，还要确认序列号
- 二次握手出现的问题：
  - 客户端与服务端建立连接，只是做了简单的通信后，结束了连接；
  - 如果客户端连接请求，但因请求报文丢失而未收到确认，于是客户端重传一次连接请求；
  - 建立连接后，客户端与服务端只是做了简单的通信，结束了连接；
  - 假如第一个丢失的报文段只是在某些网络结点长时间滞留了，在上面的连接结束后来到了服务端；
  - 因为不采用三次握手，只有服务端发出确认，就建立新的连接；
  - 此时客户已经关闭，服务端一直等待客户端发送数据，浪费资源；
- 为什么不需要四次：
  - 大部分情况下，客户端与服务端建立连接后，客户端会马上发送数据的，一旦客户端发送数据，很多问题都得到解决
  - 假如客户端发给服务端的应答丢了，当客户端后续发送的数据到达时，服务端认为这个连接已经建立了
  - 假如服务端挂了，客户端发送的数据，会报错，说目标不可达

##### 为什么需要四次挥手？

- 因为当服务端收到客户端的`SYN`连接请求报文后，可以直接发送`SYN+ACK`报文；
  - 其中`ACK`报文是用来应答的，`SYN`报文是用来同步的。
- 但是关闭连接时，当服务端收到`FIN`报文时，很可能并不会立即关闭`socket`；
- 所以只能先回复一个`ACK`报文，告诉客户端：你的`FIN`报文我收到了；
- 只有等待服务端所有的报文都发送完了，才能发送`FIN`报文，告诉客户端可以关闭了。
- 因此需要四次挥手


##### 拓展：序号(`ISN`)是固定的吗？

- 三次握手除了建立连接外，主要是为了沟通，TCP包的序号问题；
- 每个连接都要有不同的序号，这个序号的序号的起始是随着时间变化的，可以看成一个32位的计数器，每 4ms加1；
- 这样选择序号的目的在于防止网络中被延迟的分组在以后又被传送回来，而导致某个连接的一方对它做错误的解释；

##### 拓展：三次握手过程中可以携带数据吗

- 第一、二次握手不可以携带数据，而第三次握手是可以携带数据的。
- 假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器：
  - 那么他每次都在第一次握手中的`SYN`报文中放入大量的数据；
  - 因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂重复发`SYN`报文；
  - 这会让服务器花费很多时间、内存空间来接收这些报文；
  - 所有第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击；
- 第三次的话，此时客户端已经处于`ESTABLISHED`状态：
  - 已经建立起连接了，并且客户端已经知道服务器的接收、发送能力是正常的；
  - 所以能携带数据。
  
##### 拓展：状态

- `LISTEN`：侦听来自远方`TCP`端口的连接请求
- `SYN-SENT`：在发送连接请求后等待匹配的连接请求 
- `SYN-RECEIVED`：在收到和发送一个连接请求后等待对连接请求的确认
- `ESTABLISHED`：代表一个打开的连接，数据可以传送给用户；
- `FIN-WAIT-1`：等待远程 `TCP` 的连接中断请求，或先前的连接中断请求的确认；
- `FIN-WAIT-2`：从远程`TCP`等待连接中断请求
- `CLOSE-WAIT`：等待从本地用户发来的连接中断请求 
- `CLOSING`：等待远程`TCP`对连接中断的确认 
- `LAST-ACK`: 等待原来发向远程`TCP`的连接中断请求的确认
- `TIME-WAIT`: 等待足够的时间以确保远程`TCP`接收到连接中断请求的确认
- `CLOSED`: 没有任何连接状态

------

### `TCP` 怎么保证可靠传输？

- 通过序列号、重传机制、校验和、流量控制、拥塞控制实现可靠性

- 序列号
  - 应用数据被分割成 TCP认为最合适发送的数据块；
  - TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层；
  - TCP的接收端会丢弃重复的数据
- 重传机制(4种)
   - 超时重传：发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的ACK应答，就会重发该数据。
  - 快速重传：当收到三个相同的ACK报文时，会在定时器过期前，重传丢失的报文。
  - SACK(选择性确认）：和快速重传的区别是，接收方在TCP头部选项中加SACK，告诉发送方，哪些数据没有接收到，只重传丢失的数据
  - D-SACK：使用SACK告诉发送方哪些数据被重复接收了，发送的数据没丢，是ACK丢了
- 校验和
  - TCP将保持它首部和数据的校验和，发送的数据包的二进制相加然后取反；
  - 这是一个端到端的校验和，目的是检测数据在传输过程中的任何变化；
  - 如果收到段的校验和有差错，TCP将丢弃这个报文段，不确认收到此报文；
- 流量控制
  - TCP连接的每一方都有固定大小的缓冲空间，TCP头里有一个字段叫window，是接收端告诉发送端自己有多少缓冲区可以接收数据。
- 于是发送端就可以根据这个接收端的处理能力发送数据，而不会导致接收端处理不过来，导致丢包。
  - `TCP`利用滑动窗口实现流量控制；
- 拥塞控制
  - TCP维护一个拥塞窗口cwnd，用来估计在一段时间内这条链路可以承载和运算的数据的量；
  - 当出现丢包的情况，TCP就会认为网络出现拥塞，减小拥塞窗口以控制数据的发送。

------

### `TCP` 四次挥手的时候 `CLOSE_WAIT` 是怎么处理？

------

### `TCP` 四次挥手过程以及所处状态，为什么还需要有 `TIME_WAIT` ？

##### 四次挥手过程

- 如上述

##### 为什么还需要 `TIME_WAIT`(简述 `TCP` 的 `TIME_WAIT`)

- `TCP`协议规定，对于已经建立的连接，网络双方要进行四次挥手才能成功断开；
- 而`TIME_WAIT`状态则是在四次挥手后，客户端等待关闭状态，需等待`2MSL`(2个报文最大生存时间)，约4分钟：
- 原因1：主要是确保服务能收到客户端的`ACK`报文：
  - 如果没有收到的话，服务器会重新发`FIN`报文给客户端；
  - 客户端再次收到`ACK`报文后，就知道之前的`ACK`报文丢失了，需要再次发送`ACK`报文
- 原因2：等待最大`2MSL`可以使本次链接持续时间内所产生的所有报文段都从网络中消失。
  - 从而保证在关闭连接后不会有还在网络中滞留的报文段去骚扰服务器
  - 解释：如果不等，释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老`TCP`报文可能与新`TCP`报文冲突，造成数数据冲突。

##### 拓展：`MSL`

- 报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃

------

### 简述 `OSI` 七层模型，`TCP、UDP` 属于哪一层？他们之间有什么区别？

##### 七层协议

- 应用层：文件传输、文件服务等功能
- 表示层：数据格式化，代码转换，数据加密
- 会话层：解除或建立与别的接点的联系
- 传输层：提供端对端的接口
- 网络层：为数据包选择路由
- 数据链路层：传输有地址的帧以及错误检测功能
- 物理层：以二进制数据形式在物理媒体上传输数据

##### TCP和UDP属于传输层

##### TCP和UDP的区别

|              | UDP                                      | TCP                                    |
| ------------ | ---------------------------------------- | -------------------------------------- |
| 是否连接     | 无连接                                   | 面向连接                               |
| 是否可靠     | 不可靠传输，不使用流量控制和拥塞控制     | 可靠传输，使用流量控制和拥塞控制       |
| 连接对象个数 | 支持1对1，1对多，多对1，多对多交互通信   | 只能一对一通信                         |
| 传输方式     | 面向报文                                 | 面向字节流                             |
| 首部开销     | 首部开销小，仅8字节                      | 首部最小20字节，最大60字节             |
| 使用场景     | 适用实时应用（IP电话、视频会议、直播等） | 使用要求可靠传输的应用，例如：文件传输 |



------

### `TCP` 的拥塞控制具体是怎么实现的？ `UDP`有拥塞控制吗？

##### 实现

- `TCP`维护一个拥塞窗口`cwnd`，用来估计在一段时间内这条链路可以承载和运算的数据的量；
- 拥塞窗口的大小取决于网络的拥塞程度，并动态地变化；
- 我们该如果直到这条水管的运送效率是多少，可以通过`Reno`和`BBR`算法去控制

#### `UDP`有拥塞控制吗

- 没有
- `UDP`是面向报文的，`UDP`对应用层下来的报文既不合并也不拆分，一次交付一个完整的报文；
- `UDP`发送不保证不丢失，不保证按顺序到达，所以`UDP`是没有拥塞控制的；
- 很多实时应用要求主机恒定速率发送数据，并且在拥塞时丢失数据，很适合`UDP`；

------

### `TCP` 中常见的拥塞控制算法有哪些？

##### Reno(linux 默认)

- 使用低延时低带宽的网络，分包含四个算法
- 慢启动算法：
  - TCP连接刚建立，先探测一下网络的拥塞程度，由小到大逐渐增加拥塞窗口的大小；
  - 初始化拥塞窗口(大小为1、2、3、4、10都有)，每收到一个ACK就将拥塞窗口大小加一(cwnd = cwnd + 1)(1 MSS，最大单个报文段长度)；
  - 每当过了一个往返时延RTT，窗口大小翻倍( x2)
  - 若窗口大小(cwnd) >= 慢启动阈值(ssthresh)时，进入拥塞避免算法
- 拥塞避免算法：
  - 每收到一个ACK，窗口大小增加 1/cwnd;
  - 每当过了一个往返时延RTT，窗口大小 + 1
- 拥塞检测算法
  - TCP拥塞控制默认网络丢包是由于网络拥塞导致的，以丢包为进入拥塞状态的信号，对于丢包有两种判断方式：
  - 超时重传RTO(发送一个数据后开启计时器，在一定时间内如果没有得到ACK报文，那么重新发送数据) 
  - 发送端收到3个重复的ACK(TCP就意识到数据发生丢失，需要重传，不需要等待超时)
    - 拥塞窗口减半(cwnd/=2)
    - 慢启动阈值等于拥塞窗口(ssthresh=cwnd)
    - 进入快速恢复算法
 - 快速恢复算法
   - 首先进行快速重传(要求接收方在收到一个失序的报文端后就立即发出确认，而不要等到自己发送数据时捎带确认)
   - 如果收到之前重复的ACK，则窗口+1
   - 如果收到是新的ACK，则表明包成功了，将拥塞窗口设置为慢启动阈值，然后进入拥塞避免算法。
   
##### BRR

- 周期性地探测网络得容量，交替测量一段时间内得带宽极大值和时延极小值，将其乘积作为拥塞窗口大小，使得拥塞窗口的值始终与网络的容量保持一致
- 解决的问题：
  - 在有一定丢包率的网络链路上充分利用带宽(适合高延迟、高带宽的网络链路)
  - 降低网络链路上的buffer占用率，从而降低延迟(适合慢速接入网络的用户)

##### RTT(往返时延)

- 从发送端发送数据开始，到发送端收到接收方的确认，总共经历的时延
- 样本值

------

### 简述 `TCP` 滑动窗口以及重传机制

##### 滑动窗口

- 滑动窗口用于网络数据传输时的流量控制，以避免拥塞的发生。
- TCP连接的每一方都有固定大小的缓冲空间，TCP头里有一个字段叫window，是接收端告诉发送端自己有多少缓冲区可以接收数据。
- 于是发送端就可以根据这个接收端的处理能力发送数据，而不会导致接收端处理不过来，导致丢包。

##### 重传机制

- `TCP`协议是一种面向连接的可靠的传输层协议，它保证了数据的可靠传输；
- 对于一些出错，超时丢包等问题，`TCP`通过重传机制进行解决。
- 重传机制有四种：
  - 超时重传：发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的ACK应答，就会重发该数据。
  - 快速重传：当收到三个相同的ACK报文时，会在定时器过期前，重传丢失的报文。
  - SACK(选择性确认）：和快速重传的区别是，接收方在TCP头部选项中加SACK，告诉发送方，哪些数据没有接收到，只重传丢失的数据
  - D-SACK：使用SACK告诉发送方哪些数据被重复接收了，发送的数据没丢，是ACK丢了

------

### `TCP` 的 `keepalive` 了解吗？说一说它和 `HTTP` 的 `keepalive` 的区别？

##### `TCP`的`keepalive`

- 用于保活探测，当一个`TCP`连接客户端很久没有向服务端发送数据了，服务端需要确认客户端还在不在，会自动发送一个数据为空的侦测报文，如果重试多次都没有返回时，认为没必要保持连接
  - `tcp_keepalive_time`:闲置多少时间就发送探测包
  - `tcp_keepalive_intvl`:间隔多少时间发送一次探测包
  - `tcp_keepalive_probes`:尝试多少次探测包后，认为没有必要保持连接

##### 与`HTTP`的`keepalive`的区别

- `HTTP`的`keepalive`是为了连接复用，节省同一客户端多个请求创建连接和关闭连接的开销
- `TCP`的`keepalive`是保活探测，确认客户端是否还在线

------

### 从系统层面上，`UDP`如何保证尽量可靠？

------

### 什么是 `TCP` 粘包和拆包？

- 拆包：
  - `TCP`会把发送的数据分为合适的大小发送，当数据量太大是，会进行拆分发送
- 粘包：
  - 两个独立业务的请求数据包，可能会合在一起发送，当数据包较小或者当发送速度大于接收方的处理速度，会发生粘包  

------

### 简述 `TCP` 协议的延迟 `ACK` 和累计应答

##### 累计应答

- 在 `TCP`传输中，为了保证顺序性，每一个包都有一个`ID`；
- 在建立连接的时候，会商定起始的`ID`是什么，然后按照`ID`一个一个发送；
- 为了保证不丢包，对于发送的包都要进行应答，但是这个应答不是一个一个来的，而是会应答某个之前的`ID`,表示都收到了；
- 这种模式称为累计确认或者累计应答

------

### 简述 `TCP` 的报文头部结构

- 源端口号(`16`位)和目标端口号(`16`位)
  - 数据发送的应用
- 包的序号(`32`位)
  - 解决乱序的问题
- 确认序号(`32`位)
  - 解决丢包问题
  - 发出去的包应该有确认，如果没有收到确认就应该重新发送，直到送达
- 状态位
  - SYN：是发起一个连接
  - ACK：是回复
  - RST：是重新连接
  - FIN：是结束连接
  - TCP是面向连接的，双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更
- 窗口大小
  - TCP做流量控制，通信双各声明一个窗口，标识自己当前能够处理的能力，发送多少数据
  - TCP 做拥塞控制，控制发送的速度

------

### 简述 `TCP` 半连接发生场景

- 服务器第一次接收客户端的 `SYN`之后，就会处于`SYN_RCVD`状态，此时双方还没有完全建立其连接，这种状态称为半连接；
- 服务器会把此状态下请求连接放在一个队列离，我们把这个队列称为半连接队列

##### 拓展：`SYN_ACK`重传与半连接的关联

- 服务器发送完`SYN_ACK`包，如果未收到客户端确认包，服务器进行首次重传；
- 等待一段时间仍未收到客户端确认包，进行第二次重传；
- 如果重传次数超过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除

##### 拓展：全连接队列

- 已经完成三次握手，建立起连接的就会放在全连接队列中
- 如果队列满了，就有可能出现丢包现象。

------

### `TCP` 在什么情况下服务端会出现大量 `CLOSE_WAIT` ？

------

### 什么是 `SYN flood`，如何防止这类攻击？

##### 概念

- 服务器的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易收到`SYN`洪泛攻击。
- `SYN`攻击就是客户端在短时间内伪造大量不存在的`IP`地址，并向服务端不断发送`SYN`包：
  - 服务端回复确认包，并等待客户端确认；
  - 由于源地址不存在，因此服务端需要不断重发直至超时；
  - 这些伪造的`SYN`包将长时间占用为连接队列，导致正常的`SYN`请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。

##### 防止

- 缩短超时(`SYN Timeout`)时间
- 增加最大半连接数
- 过滤网关防护
- `SYN cookies` 技术

------

## `HTTP`

### `HTTP` 与 `HTTPS` 有哪些区别？

- 安全性：`HTTP`数据传输是未加密的，安全性较差；`HTTPS`数据传输是加密的，安全性较好；
- 证书：HTTP无，HTTPS需要数字认证机构申请证书；
- 建立连接的端口不一样：HTTP是无状态的，默认是80端口；HTTPS是SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，默认是443端口；
- 页面加载：`HTTP`比`HTTPS`快，因为`HTTPS`比`HTTP`的三次握手，多了`SSL`协商过程

------

### 简述 `HTTP 1.0，1.1，2.0` 的主要区别

#### HTTP/1.0

##### 存在缺陷：

- 浏览器的每次请求都需要与服务器建立一个TCP连接，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。
- TCP连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢(slow start)

##### 解决方式：

- 添加信息：非标准的Connection字段`Connection:keep-alive`

#### HTTP/1.1

##### 改进点

- 1-引入持久连接，即TCP连接默认不关闭，可以被多个请求复用，不用声明 `Connection:keep-alive`

  - 客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。规范的做法是，客户端在最后一个请求时，发送 `Connection:close`， 明确要求服务器关闭TCP连接
  - 对于同一个域名，大多数浏览器允许同时建立6个持久连接

- 2-引入管道机制，即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进HTTP协议

  - 以前的机制是客户请求两个资源，先发送A请求，然后等待服务器做出回应，收到后在发出B请求。
  - 管道机制则允许浏览器同时发出A和B请求，但服务器还是按照顺序，先回应A请求，完成后再回应B请求

- 3-引入分块传输，采用流模式(stream)取代缓存模式(buffer)，服务器产生一块数据，就发送一块
  - 请求回回应的头信息有`Transfer-Encoding`字段，就表明回应将由数量未定的数据块组成
- 4-其他功能：增加PUT(请求服务器存储一个资源)、OPTIONS(请求查询服务器的性能)、DELETE(请求服务器删除标识的资源)方法，客户端请求的头信息新增HOST字段，用来指定服务器的域名

##### 缺点：

- 虽然允许复用TCP连接，但是同一个TCP连接里，所有的数据通信是按次序进行的。服务器只能处理完一个请求，才会进行下一个请求。如果前面的回应特别慢，后面就会有许多请求排队等着。这将导致对头阻塞。

##### 避免方法

- 减少请求数
- 同时多开持久连接

#### HTTP/2.0

- 1- 采用二进制格式而非文本格式
  - HTTP/1.1的头信息是文本(ASCII编码)，数据体可以是文本，也可以是二进制。HTTP/2.0头信息和数据体都是二进制，并且统称为帧(frame)：头信息帧和数据帧
  - 二进制协议解析起来更高效
- 2- 完全多路复用
  - HTTP/2.0复用TCP连接，在一个连接里，客户端和服务器可以同时发送多个请求或回应，而且不用按照顺序一一对应，避免队头堵塞。
- 3- 请求数据流进行标号，可以取消某次请求，也可以指定数据流的优先级，优先级高，服务器就会越早回应
  - 每个请求或回应的所有数据包，称一个数据流，有独一无二的编号 
- 4-头信息压缩
  - HTTP协议是没有状态的，导致每次请求都必须附上所有信息。所以请求的很多字段都是重复的，比如Cookie，每次请求都必须附带，会浪费很多带宽，也影响速度
  - HTTP/2.0引入头信息压缩机制，一方面，头信息使用gzip或compress压缩后再发送，另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生存一个索引号，以后就不发生同样字段了，只发送索引号，这样就提高了速度。
- 5-服务器推送
  - HTTP/2允许服务器未经请求，主动向客户端发送资源
  - 通过推送那么服务器认为客户端将会需要的内容到客户端的缓存种，避免往返的迟延

------

### `HTTP` 的方法有哪些？

------

### 简述 `HTTPS` 的加密与认证过程

------

### 简述常见的 `HTTP` 状态码的含义（`301，304，401，403`）

------

### `Cookie` 和 `Session` 的关系和区别是什么？

------

## `RestFul/RPC`

### `RestFul` 是什么？`RestFul` 请求的 `URL` 有什么特点？

##### `RESTful`是什么

- 首先说一下`REST`，它是以设计风格，描述的是在网络中客户端和服务器的一种交互形式；
- `REST`是将`URL`的命名风格、对资源的操作的实现方式、操作后返回什么信息，和资源以哪种形式表现出来等，总结成一种设计风格；
- 满足这种设计风格的程序或接口，我们称之为`RESTful`

##### 特点

- 利用`HTTP`方法让接口统一化
  - `REST`充分利用`HTTP`自身的`GET、POST、PUT、DELETE`的方法实现接口的统一化
- 利用`HTTP`状态码返回状态信息
  - 其中`2XX`的状态码表示请求已经成功被服务器接收、理解、并接受
  - `3XX`的状态码表示重定向
  - `4XX`的状态码表示客户端错误
  - `5XX`的状态码表示服务器错误
- 利用`HTTP`报头告知对方如何处理本次请求
  - `HTTP`报头是描述客户端与服务器之间的请求或响应应该如何处理本次请求
  - `Authorization` 认证报头等
- `REST`设计风格要求服务器无状态
  - 指服务器不保存请求状态(会话信息)，客户端必须每次都带上自己的状态去请求服务器

------

### `RESTful` 与 `RPC` 的区别是什么？`RESTful` 的优点在哪里？

##### 区别

- 1 所属类别不同
  - REST 是表述性状态传递，是指某个瞬间状态的资源数据，包括资源数据的内容、表述格式等信息。RESTful 即实现REST设计风格的一种架构
  - RPC 是远程过程调用，它可以实现客户端像调用本地方法一样调用服务器的方法
- 2 使用方式不同
  - REST 是服务端把方法写好，客户端并不知道具体方法。客户端只想获取资源，所以发起HTTP请求，而服务端接收到请求后根据URL经过一系列的路由，才定位到方法上面去
  - RPS 是 服务端提供好方法给客户端调用，客户端需要知道服务端的具体类、类方法，然后像本地方法一样调用它 
- 3 面向对象不同
  - REST是面向资源的
  - RPC 所谓的远程过程调用，是面向方法的 
- 4 序列化协议不同
  - REST 是基于 HTTP协议， 
- 5 应用场景不同

##### 优点



------

### 从输入 `URL` 到展现页面的全过程

##### 总体来说，分为以下几个过程：

- `DNS`解析：用户输入的`URL`一般是域名，而我们需要的是`IP`地址，需要从域名服务器获取对应`IP`地址；
- `TCP`连接：获取到服务器`IP`地址后，发起`TCP`连接请求，三次握手后建立连接，就可以将`HTTP`请求数据发送给服务器；
- 发送`HTTP`请求：按照`HTTP`协议标准发送数据与后端请求；
- 处理请求并返回：服务器接受并处理请求，返回客户端相应的数据
- 浏览器渲染：浏览器根据返回的数据渲染到屏幕上
- 断开连接：客户端和服务器经过`4`次挥手终止`TCP`连接

##### `DNS`解析

- 浏览器通过向`DNS`服务器发送域名，`DNS`服务器查询到与域名相对于的`IP`，然后返回给浏览器；

##### `TCP`三次握手

- 客户端与服务器双方的接收与发送能力是否正常

##### 发送`HTTP`请求

- 浏览器分析这个`URL`，并设置号报文发出，请求报文中包含：请求行、请求头、空行、请求体；`https`默认请求端口`443`,`http`默认`80`
  - 请求行：包括请求的方法、路径和协议版本
  - 请求头：包含请求的一些附加信息，一般是以键值对的形式成对存在的；比如设置请求文件类型`accept-type`等
  - 空行：协议规定请求头和请求主体间必须用一个空行隔开
  - 请求主题：对于`POST`请求，所需要的参数都不会放在`URL`中，存放在请求主体中
  
##### 服务器处理请求并返回`HTTP`报文

- 服务端收到请求后，会根据`URL`匹配的路径做相应的处理，最后返回浏览器需要的页面资源。
- 响应报文包含：响应行、响应头、空行、响应主题
  - 响应行：与请求的起始行不同的是其包含的还要状态码和状态码的原因
  - 响应头：对于请求报文中的请求头
  - 空行：
  - 报文主体：请求所需的资源
  
##### 浏览器解析渲染页面

- 浏览器拿到一个 `HTML`文档，并为了呈现文档而开始解析

##### 断开连接：`TCP`四次挥手

- 现在的页面为了优化请求的耗时，默认都会开启持久连接(`keep-alive`)，一个`TCP`连接确实关闭时机，是这个`tab`标签页的关闭

------

#### `RPC`的底层原理

------

#### 简述 `RPC` 的调用过程

------

## 其他

#### 简述对称与非对称加密的概念

#### 什么是中间人攻击？如何防止攻击？

#### 什么是跨域，什么情况下会发生跨域请求？

#### `DNS` 查询服务器的基本流程是什么？`DNS` 劫持是什么？

##### 查询流程

- 查询的基本流程是：依次从浏览器缓存、系统缓存、路由缓存、`ISP DNS`缓存、根域名服务器查找，如果上一步查找成功就直接返回，否则往下查询；

- 查找浏览器缓存
  - 如果我们以前访问过目标网站，那么在浏览器就会有相应的缓存记录；
  - 输入网址后，浏览器会首先检查缓存中是否有该域名对应的`IP`地址；
  - 如果有，则直接返回该信息供用户访问网站，如果查询失败，则进行下一步
- 查找系统缓存
  - 从`hosts`文件中查找是否有存储的`DNS`信息，如果查找失败，则进行下一步
- 查找路由器缓存
  - 如果之前访问过相应的网站，一般路由器也会有缓存信息。如果查找失败，则进行下一步
- 查找`ISP`的 `DNS`缓存
  - 从网络服务商的`DNS`缓存信息中查找
- 查找根域名服务器
  - 向根域名服务器查找域名对应的`IP`地址，根域名服务器把请求转发到下一级，逐层查找该域名的对应数据，直到获得最终解析结果或查询失败
  
##### `DNS`劫持

- 域名劫持
- 是指在劫持网络范围内拦截域名解析请求,分析请求的域名，把审查范围以外的请求放行;
- 返回假的`IP`地址或什么都不做，使请求失去响应；
- 其效果就是特定的网络不能访问或访问的是假网址。

#### 简述 `JWT` 的原理和校验机制

#### 为什么需要序列化？有什么序列化的方式？

#### 简述 `WebSocket` 是如何进行传输的
